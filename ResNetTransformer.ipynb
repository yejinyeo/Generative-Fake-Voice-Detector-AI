{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "361d73a1",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2024-04-08T18:51:47.130888",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.123877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f23c11-c397-46de-99fd-4ecc35ae117e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\yedin\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from lazy-loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797c6f40-5382-4af5-8379-3eed1a4d0e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\yedin\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193d7991-9c41-4def-9163-bf7c34bacd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\users\\yedin\\anaconda3\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torchmetrics) (2.3.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torchmetrics) (0.11.3.post0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\yedin\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbadbd56",
   "metadata": {
    "papermill": {
     "duration": 12.650384,
     "end_time": "2024-04-08T18:51:59.788340",
     "exception": false,
     "start_time": "2024-04-08T18:51:47.137956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d80cf24-13e8-480c-94eb-2982bb52510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f64eb379-e527-46c4-8b12-ead8db628070",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d2de5d",
   "metadata": {
    "papermill": {
     "duration": 0.007241,
     "end_time": "2024-04-08T18:51:59.803571",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.796330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a32fb60",
   "metadata": {
    "papermill": {
     "duration": 0.016983,
     "end_time": "2024-04-08T18:51:59.828208",
     "exception": false,
     "start_time": "2024-04-08T18:51:59.811225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = './'\n",
    "    # Training\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 96\n",
    "    N_EPOCHS = 10\n",
    "    LR = 3e-4\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc9217-3286-439b-9727-0cec4756d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = 'open.zip'\n",
    "extract_path = 'datasets'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f91b8880-edb9-4976-b384-678e609972ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: C:\\Users\\yedin\\generative-fake-voice-detector-ai\\datasets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 변경할 디렉토리 경로를 지정합니다.\n",
    "new_path = './datasets'\n",
    "\n",
    "# 작업 디렉토리를 변경합니다.\n",
    "os.chdir(new_path)\n",
    "\n",
    "# 현재 작업 디렉토리를 확인합니다.\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89915bfa-46fa-407e-b8f0-6a800458a766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>SNGJTJQG</td>\n",
       "      <td>./train/SNGJTJQG.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>LIYTDJZZ</td>\n",
       "      <td>./train/LIYTDJZZ.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55413</th>\n",
       "      <td>HAMPQOIN</td>\n",
       "      <td>./train/HAMPQOIN.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>UCJMLYVH</td>\n",
       "      <td>./train/UCJMLYVH.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33027</th>\n",
       "      <td>EUKZRQPD</td>\n",
       "      <td>./train/EUKZRQPD.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>PWTCAYUB</td>\n",
       "      <td>./train/PWTCAYUB.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54343</th>\n",
       "      <td>HSAHCTUQ</td>\n",
       "      <td>./train/HSAHCTUQ.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>CXJSUSJK</td>\n",
       "      <td>./train/CXJSUSJK.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>ZBTGTORE</td>\n",
       "      <td>./train/ZBTGTORE.ogg</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>LXIOTYEX</td>\n",
       "      <td>./train/LXIOTYEX.ogg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44350 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                  path label\n",
       "6804   SNGJTJQG  ./train/SNGJTJQG.ogg  fake\n",
       "3734   LIYTDJZZ  ./train/LIYTDJZZ.ogg  fake\n",
       "55413  HAMPQOIN  ./train/HAMPQOIN.ogg  real\n",
       "10741  UCJMLYVH  ./train/UCJMLYVH.ogg  fake\n",
       "33027  EUKZRQPD  ./train/EUKZRQPD.ogg  real\n",
       "...         ...                   ...   ...\n",
       "44732  PWTCAYUB  ./train/PWTCAYUB.ogg  fake\n",
       "54343  HSAHCTUQ  ./train/HSAHCTUQ.ogg  real\n",
       "38158  CXJSUSJK  ./train/CXJSUSJK.ogg  fake\n",
       "860    ZBTGTORE  ./train/ZBTGTORE.ogg  real\n",
       "15795  LXIOTYEX  ./train/LXIOTYEX.ogg  fake\n",
       "\n",
       "[44350 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c160015d-fedd-42af-8c5e-4d5403425f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 27620, Fake: 27818\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불균형 확인\n",
    "real_count = len(df[df['label'] == 'real'])\n",
    "fake_count = len(df[df['label'] == 'fake'])\n",
    "print(f\"Real: {real_count}, Fake: {fake_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629d3d15-b971-49e2-a410-71b4cd9cbcf4",
   "metadata": {},
   "source": [
    "## Data Pre-processing : MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89473faf-dccc-42dd-8910-dac8edb26d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: C:\\Users\\yedin\\generative-fake-voice-detector-ai\\datasets\n"
     ]
    }
   ],
   "source": [
    "# 현재 작업 디렉토리를 확인합니다.\n",
    "current_directory = os.getcwd()\n",
    "print(\"현재 작업 디렉토리:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3bf9a44-d7e7-4253-9e56-eaf7ad6870c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상대 경로를 절대 경로로 변환합니다.\n",
    "relative_path = 'generative-fake-voice-detector-ai/datasets'\n",
    "absolute_path = os.path.abspath(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1bdd0ba-fe6e-4efa-b785-af0389c50b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_feature(df, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        y, sr = librosa.load(row['path'], sr=CONFIG.SR)\n",
    "        if train_mode:\n",
    "            y = augment_audio(y, sr)  # sr 추가\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc = np.mean(mfcc.T, axis=0)\n",
    "        features.append(mfcc)\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "74b268a8-1e8b-4251-ace3-47866ab2e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 함수\n",
    "def augment_audio(y, sr):  # sr 추가\n",
    "    aug_choice = random.choice(['time_stretch', 'pitch_shift', 'add_noise', 'shift'])\n",
    "    if aug_choice == 'time_stretch':\n",
    "        rate = random.uniform(0.8, 1.2)\n",
    "        y = librosa.effects.time_stretch(y, rate=rate)  # rate를 키워드 인자로 전달\n",
    "    elif aug_choice == 'pitch_shift':\n",
    "        steps = random.randint(-5, 5)\n",
    "        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)  # sr과 n_steps 추가\n",
    "    elif aug_choice == 'add_noise':\n",
    "        noise = np.random.randn(len(y))\n",
    "        y = y + 0.005 * noise\n",
    "    elif aug_choice == 'shift':\n",
    "        shift = np.random.randint(len(y))\n",
    "        y = np.roll(y, shift)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c5efb058-b659-48bc-a7f8-9e27211ef21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44350it [19:11, 38.52it/s]\n",
      "11088it [2:48:56,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a682d49",
   "metadata": {
    "papermill": {
     "duration": 0.007331,
     "end_time": "2024-04-08T18:52:31.507909",
     "exception": false,
     "start_time": "2024-04-08T18:52:31.500578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2459913-1bf6-40b9-b07d-402699590b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mfcc, label):\n",
    "        self.mfcc = mfcc\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            # 차원을 (Batch, Channel, Height, Width) 형식으로 변경하고 채널을 3개로 복제\n",
    "            mfcc = torch.tensor(self.mfcc[index], dtype=torch.float32).unsqueeze(0)\n",
    "            mfcc = mfcc.expand(3, -1, -1)  # 채널을 3개로 복제\n",
    "            return mfcc, torch.tensor(self.label[index], dtype=torch.float32)\n",
    "        mfcc = torch.tensor(self.mfcc[index], dtype=torch.float32).unsqueeze(0)\n",
    "        mfcc = mfcc.expand(3, -1, -1)  # 채널을 3개로 복제\n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c7a462f-e4b3-44d8-8eef-16000d3124d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
    "val_dataset = CustomDataset(val_mfcc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dff1c7df-fbe7-4a61-9f66-c55138697eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb3435-cdb7-4a31-b7ef-fc16237cfc4a",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d805d7e-c244-4d3e-930f-580eb7d4ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetTransformer, self).__init__()\n",
    "        self.resnet = models.resnet101(pretrained=True)  # 더 깊은 ResNet-101 사용\n",
    "        self.resnet.fc = nn.Identity()  # Fully connected layer 제거\n",
    "        self.fc1 = nn.Linear(2048, 512)  # ResNet-101은 2048차원 출력\n",
    "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=6)\n",
    "        self.fc2 = nn.Linear(512, CONFIG.N_CLASSES)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.batchnorm = nn.BatchNorm1d(512)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.fc1(x)\n",
    "        x = x.unsqueeze(1)  # (Batch, Channel, Features)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Global average pooling\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11408349-1988-4bef-9660-f567a7049fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Loss 정의\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        BCE_loss = self.bce(logits, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=1, gamma=2)  # Focal Loss 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c4a8c-0219-46bd-bd46-09d0327fe7eb",
   "metadata": {},
   "source": [
    "# Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2a7253de-ce9a-45a8-b71f-7752e427941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(iter(train_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)  # Focal Loss 적용\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    return best_model\n",
    "\n",
    "def multiLabel_AUC(y_true, y_scores):\n",
    "    auc_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score\n",
    "    \n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(iter(val_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            probs = model(features)\n",
    "            loss = criterion(probs, labels)\n",
    "            val_loss.append(loss.item())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
    "    return _val_loss, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a482219-ce5e-47ce-90cc-564ceb4e46ff",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e97644a0-2385-4e16-ab02-ecf787ac061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\yedin/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 171M/171M [00:10<00:00, 16.3MB/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:02<00:00,  1.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:17<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.15565] Val Loss : [0.19130] Val AUC : [0.49657]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:10<00:00,  1.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.17962] Val Loss : [0.17341] Val AUC : [0.55774]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:40<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:17<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.17500] Val Loss : [0.17334] Val AUC : [0.53486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:38<00:00,  1.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.17476] Val Loss : [0.17400] Val AUC : [0.46406]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:46<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.17493] Val Loss : [0.17353] Val AUC : [0.46277]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:43<00:00,  1.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.17488] Val Loss : [0.17335] Val AUC : [0.52135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:40<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:17<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.17503] Val Loss : [0.17339] Val AUC : [0.47563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:53<00:00,  1.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.17479] Val Loss : [0.17330] Val AUC : [0.48040]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:42<00:00,  1.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.17490] Val Loss : [0.17354] Val AUC : [0.51815]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 462/462 [06:32<00:00,  1.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 116/116 [00:16<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.17491] Val Loss : [0.17333] Val AUC : [0.47604]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ResNetTransformer()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978b0e6-b773-423a-93e4-ce463f4d4d84",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76141516-342f-4f0f-8f75-20700f284792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [12:13, 68.17it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "test_mfcc = get_mfcc_feature(test, False)\n",
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5889b493-d760-4cac-9ced-c3715195e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(test_loader)):\n",
    "            features = features.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd74fe5f-82f1-4ad7-818f-509e1bea642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 521/521 [01:11<00:00,  7.30it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fae66d-8f54-46d5-9201-0f4b0db76e76",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3f8314c4-1dce-4f79-9f3d-77d320a3746e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>0.501809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>0.501809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>0.501809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>0.501809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.498192</td>\n",
       "      <td>0.501809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      fake      real\n",
       "0  TEST_00000  0.498192  0.501809\n",
       "1  TEST_00001  0.498192  0.501809\n",
       "2  TEST_00002  0.498192  0.501809\n",
       "3  TEST_00003  0.498192  0.501809\n",
       "4  TEST_00004  0.498192  0.501809"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission_1.csv')\n",
    "submit.iloc[:, 1:] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e28d71bc-6703-40f7-9716-a0ef897eca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./baseline_submit_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513134e9-1483-473d-9143-549dafaa41ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "datasetId": 4732842,
     "sourceId": 8066583,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1830.928153,
   "end_time": "2024-04-08T19:22:15.265404",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T18:51:44.337251",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a8f214ec354c44b73d439565382278": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06a1ede084cd487ebf3c469be657b53e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80013ce73542415e82be091acccb89fe",
        "IPY_MODEL_d280070ca871485fbd2b7d34b1c9fd10",
        "IPY_MODEL_8212bde7695f494cbabea66983e4cf29"
       ],
       "layout": "IPY_MODEL_c4da594b806c4c2bbff6e8cdaf6088eb"
      }
     },
     "37e28ba3d8564da4a3257c3729310584": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80013ce73542415e82be091acccb89fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95e72a34a4374fd5b4b147772085bb7c",
       "placeholder": "​",
       "style": "IPY_MODEL_37e28ba3d8564da4a3257c3729310584",
       "value": "model.safetensors: 100%"
      }
     },
     "8212bde7695f494cbabea66983e4cf29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d9e4e04bb60e40d6b46d782f8156d05f",
       "placeholder": "​",
       "style": "IPY_MODEL_b1fa83d0511a4d8a910b8fdb40d32c29",
       "value": " 36.5M/36.5M [00:01&lt;00:00, 41.1MB/s]"
      }
     },
     "95e72a34a4374fd5b4b147772085bb7c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1fa83d0511a4d8a910b8fdb40d32c29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c4da594b806c4c2bbff6e8cdaf6088eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d280070ca871485fbd2b7d34b1c9fd10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01a8f214ec354c44b73d439565382278",
       "max": 36494688,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dcd2393d73d14514851a7d9ef50315fc",
       "value": 36494688
      }
     },
     "d9e4e04bb60e40d6b46d782f8156d05f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcd2393d73d14514851a7d9ef50315fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
